{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some utils related to Keras models.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "\n",
    "def load_weights(model, filepath, layer_names=None):\n",
    "    \"\"\"Loads layer weights from a HDF5 save file.\n",
    "     \n",
    "    # Arguments\n",
    "        model: Keras model\n",
    "        filepath: Path to HDF5 file\n",
    "        layer_names: List of strings, names of the layers for which the \n",
    "            weights should be loaded. List of tuples \n",
    "            (name_in_file, name_in_model), if the names in the file differ \n",
    "            from those in model.\n",
    "    \"\"\"\n",
    "    filepath = os.path.expanduser(filepath)\n",
    "    f = h5py.File(filepath, 'r')\n",
    "    if layer_names == None:\n",
    "        layer_names = [s.decode() for s in f.attrs['layer_names']]\n",
    "    for name in layer_names:\n",
    "        if type(name) in [tuple, list]:\n",
    "            layer_name = name[1]\n",
    "            name = name[0]\n",
    "        else:\n",
    "            layer_name = name\n",
    "        g = f[name]\n",
    "        weights = [np.array(g[wn]) for wn in g.attrs['weight_names']]\n",
    "        try:\n",
    "            layer = model.get_layer(layer_name)\n",
    "            #assert layer is not None\n",
    "        except:\n",
    "            print('layer missing %s' % (layer_name))\n",
    "            print('    file  %s' % ([w.shape for w in weights]))\n",
    "            continue\n",
    "        try:\n",
    "            #print('load %s' % (layer_name))\n",
    "            layer.set_weights(weights)\n",
    "        except Exception as e:\n",
    "            print('something went wrong %s' % (layer_name))\n",
    "            print('    model %s' % ([w.shape.as_list() for w in layer.weights]))\n",
    "            print('    file  %s' % ([w.shape for w in weights]))\n",
    "            print(e)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def calc_memory_usage(model, batch_size=1):\n",
    "    \"\"\"Compute the memory usage of a keras modell.\n",
    "    \n",
    "    # Arguments\n",
    "        model: Keras model.\n",
    "        batch_size: Batch size used for training.\n",
    "    \n",
    "    source: https://stackoverflow.com/a/46216013/445710\n",
    "    \"\"\"\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        shapes_mem_count += np.sum([np.sum([np.prod(s[1:]) for s in n.output_shapes]) for n in l._inbound_nodes])\n",
    "        \n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "    \n",
    "    # each shape unit occupies 4 bytes in memory\n",
    "    total_memory = 4.0 * batch_size * (shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    \n",
    "    for s in ['Byte', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if total_memory > 1024:\n",
    "            total_memory /= 1024\n",
    "        else:\n",
    "            break\n",
    "    print('model memory usage %8.2f %s' % (total_memory, s))\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "    \n",
    "    print('trainable     {:>16,d}'.format(trainable_count))\n",
    "    print('non-trainable {:>16,d}'.format(non_trainable_count))\n",
    "\n",
    "\n",
    "def plot_parameter_statistic(model, layer_types=['Dense', 'Conv2D'], trainable=True, non_trainable=True, outputs=False):\n",
    "    layer_types = [l.__name__ if type(l) == type else l for l in layer_types]\n",
    "    \n",
    "    def get_layers_recursion(model):\n",
    "        layers = []\n",
    "        for l in model.layers:\n",
    "            if l.__class__.__name__ is 'Model':\n",
    "                child_layers = get_layers_recursion(l)\n",
    "            else:\n",
    "                child_layers = [l]\n",
    "            for cl in child_layers:\n",
    "                if cl not in layers:\n",
    "                    layers.append(cl)\n",
    "        return layers\n",
    "    \n",
    "    layers = get_layers_recursion(model)\n",
    "    \n",
    "    layers = [l for l in layers if l.__class__.__name__ in layer_types]\n",
    "    names = [l.name for l in layers]\n",
    "    y = range(len(names))\n",
    "    \n",
    "    plt.figure(figsize=[12,max(len(y)//4,1)])\n",
    "    \n",
    "    offset = np.zeros(len(layers), dtype=int)\n",
    "    legend = []\n",
    "    if trainable:\n",
    "        counts_trainable = [np.sum([K.count_params(p) for p in set(l.trainable_weights)]) for l in layers]\n",
    "        plt.barh(y, counts_trainable, align='center', color='#1f77b4')\n",
    "        offset += np.array(counts_trainable, dtype=int)\n",
    "        legend.append('trainable')\n",
    "    if non_trainable:\n",
    "        counts_non_trainable = [np.sum([K.count_params(p) for p in set(l.non_trainable_weights)]) for l in layers]\n",
    "        plt.barh(y, counts_non_trainable, align='center', color='#ff7f0e',  left=offset)\n",
    "        offset += np.array(counts_non_trainable, dtype=int)\n",
    "        legend.append('non-trainable')\n",
    "    if outputs:\n",
    "        counts_outputs = [np.sum([np.sum([np.prod(s[1:]) for s in n.output_shapes]) for n in l._inbound_nodes]) for l in layers]\n",
    "        plt.barh(y, counts_outputs, align='center', color='#2ca02c', left=offset)\n",
    "        offset += np.array(counts_outputs, dtype=int)\n",
    "        legend.append('outputs')\n",
    "        \n",
    "    plt.yticks(y, names)\n",
    "    plt.ylim(y[0]-1, y[-1]+1)\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.legend(legend)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calc_receptive_field(model, layer_name, verbose=False):\n",
    "    \"\"\"Calculate the receptive field related to a certain layer.\n",
    "    \n",
    "    # Arguments\n",
    "        model: Keras model.\n",
    "        layer_name: Name of the layer.\n",
    "    \n",
    "    # Return\n",
    "        rf: Receptive field (w, h).\n",
    "        es: Effictive stides in the input image.\n",
    "        offset: Center of the receptive field associated with the first unit (x, y).\n",
    "    \"\"\"\n",
    "    # TODO...\n",
    "    \n",
    "    fstr = '%-20s %-16s %-10s %-10s %-10s %-16s %-10s %-16s'\n",
    "    if verbose:\n",
    "        print(fstr % ('name', 'type', 'kernel', 'stride', 'dilation', 'receptive field', 'offset', 'effective stride'))\n",
    "    l = model.get_layer(layer_name)\n",
    "    rf = np.ones(2)\n",
    "    es = np.ones(2)\n",
    "    offset = np.zeros(2)\n",
    "    \n",
    "    while True:\n",
    "        layer_type = l.__class__.__name__\n",
    "        k, s, d = (1,1), (1,1), (1,1)\n",
    "        p = 'same'\n",
    "        if layer_type in ['Conv2D']:\n",
    "            k = l.kernel_size\n",
    "            d = l.dilation_rate\n",
    "            s = l.strides\n",
    "            p = l.padding\n",
    "        elif layer_type in ['MaxPooling2D', 'AveragePooling2D']:\n",
    "            k = l.pool_size\n",
    "            s = l.strides\n",
    "            p = l.padding\n",
    "        elif layer_type in ['ZeroPadding2D']:\n",
    "            p = l.padding\n",
    "        elif layer_type in ['InputLayer', 'Activation', 'BatchNormalization']:\n",
    "            pass\n",
    "        else:\n",
    "            print('unknown layer type %s %s' % (l.name, layer_type))\n",
    "            \n",
    "        k = np.array(k)\n",
    "        s = np.array(s)\n",
    "        d = np.array(d)\n",
    "        \n",
    "        ek = k + (k-1)*(d-1) # effective kernel size\n",
    "        rf = rf * s + (ek-s)\n",
    "        es = es * s\n",
    "        \n",
    "        if p == 'valid':\n",
    "            offset += ek/2\n",
    "            print(ek/2, offset)\n",
    "        if type(p) == tuple:\n",
    "            offset -= [p[0][0], p[1][0]]\n",
    "            print([p[0][0], p[1][0]], offset)\n",
    "        \n",
    "        rf = rf.astype(int)\n",
    "        es = es.astype(int)\n",
    "        #offset = offset.astype(int)\n",
    "        if verbose:\n",
    "            print(fstr % (l.name, l.__class__.__name__, k, s, d, rf, offset, es))\n",
    "        \n",
    "        if layer_type == 'InputLayer':\n",
    "            break\n",
    "        \n",
    "        input_name = l.input.name.split('/')[0]\n",
    "        input_name = input_name.split(':')[0]\n",
    "        l = model.get_layer(input_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
