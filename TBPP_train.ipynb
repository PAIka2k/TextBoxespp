{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from model import TBPP384\n",
    "from tbpp_prior import PriorUtil\n",
    "from tbpp_data import InputGenerator\n",
    "from tbpp_training import TBPPFocalLoss\n",
    "from utils.model import load_weights\n",
    "from utils.training import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check using devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4907133632768135694\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2518925033299319451\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15739487107650835827\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15658998170\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9139163663857341384\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 3e94:00:00.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_synthtext import GTUtility\n",
    "gt_util = GTUtility('data/SynthText/', polygon=True)\n",
    "gt_util_train, gt_util_val = gt_util.split(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "_, image, label = gt_util_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "gt_util_train.plot_gt(label,show_labels=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label[:,6] * 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# TextBoxes++\n",
    "K.clear_session()\n",
    "model = TBPP384(softmax=False)\n",
    "weights_path = None\n",
    "\n",
    "experiment = 'tbpp384fl_synthtext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prior_util = PriorUtil(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from utils.layers import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_custom_objects().update({\n",
    "    \"Normalize\": Normalize\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model_params.json\",'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with open(\"../model_params.json\",'r') as f:\n",
    "    parameter_saved_model = model_from_json(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* checking available batch size of validation set\n",
    "\n",
    "```\n",
    "gen_val = InputGenerator(\n",
    "    gt_util_val, prior_util, batch_size*4, model.image_size)\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/utils/training.py:84: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "201911120606_tbpp384fl_synthtext\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "Epoch 1/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 44.1309WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00001: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.001.h5\n",
      "6038/6038 [==============================] - 4055s 672ms/step - loss: 44.1298 - val_loss: 38.6682\n",
      "Epoch 2/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 31.1446WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00002: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.002.h5\n",
      "6038/6038 [==============================] - 4021s 666ms/step - loss: 31.1441 - val_loss: 26.7233\n",
      "Epoch 3/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 18.8652WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00003: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.003.h5\n",
      "6038/6038 [==============================] - 3990s 661ms/step - loss: 18.8647 - val_loss: 18.5739\n",
      "Epoch 4/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 13.0849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00004: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.004.h5\n",
      "6038/6038 [==============================] - 3964s 656ms/step - loss: 13.0843 - val_loss: 15.6659\n",
      "Epoch 5/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 10.4140WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00005: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.005.h5\n",
      "6038/6038 [==============================] - 3967s 657ms/step - loss: 10.4136 - val_loss: 14.4174\n",
      "Epoch 6/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 7.9464WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00006: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.006.h5\n",
      "6038/6038 [==============================] - 3979s 659ms/step - loss: 7.9458 - val_loss: 15.2524\n",
      "Epoch 7/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 7.3289WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 7.2323WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00008: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.008.h5\n",
      "6038/6038 [==============================] - 3973s 658ms/step - loss: 7.2321 - val_loss: 15.1671\n",
      "Epoch 9/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 7.1696WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00009: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.009.h5\n",
      "6038/6038 [==============================] - 3991s 661ms/step - loss: 7.1692 - val_loss: 14.7665\n",
      "Epoch 10/10\n",
      "6037/6038 [============================>.] - ETA: 0s - loss: 7.0465WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00010: saving model to ./checkpoints/201911120606_tbpp384fl_synthtext/weights.010.h5\n",
      "6038/6038 [==============================] - 3998s 662ms/step - loss: 7.0479 - val_loss: 14.2688\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "initial_epoch = 0\n",
    "batch_size = 32\n",
    "\n",
    "gen_train = InputGenerator(gt_util_train, prior_util, batch_size, model.image_size)\n",
    "gen_val = InputGenerator(gt_util_val, prior_util, batch_size*4, model.image_size)\n",
    "\n",
    "checkdir = './checkpoints/' + time.strftime('%Y%m%d%H%M') + '_' + experiment\n",
    "if not os.path.exists(checkdir):\n",
    "    os.makedirs(checkdir)\n",
    "\n",
    "with open(checkdir+'/source.py','wb') as f:\n",
    "    source = ''.join(['# In[%i]\\n%s\\n\\n' % (i, In[i]) for i in range(len(In))])\n",
    "    f.write(source.encode())\n",
    "\n",
    "optim = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9, decay=0, nesterov=True)\n",
    "# optim = tf.keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0)\n",
    "\n",
    "# weight decay\n",
    "regularizer = tf.keras.regularizers.l2(5e-4) # None if disabled\n",
    "#regularizer = None\n",
    "for l in model.layers:\n",
    "    if l.__class__.__name__.startswith('Conv'):\n",
    "        l.kernel_regularizer = regularizer\n",
    "\n",
    "loss = TBPPFocalLoss(lambda_conf=10000.0, lambda_offsets=1.0)\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss.compute, metrics=loss.metrics)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkdir+'/weights.{epoch:03d}.h5', \n",
    "                    verbose=1, save_weights_only=True),\n",
    "    Logger(checkdir)\n",
    "]\n",
    "\n",
    "print(checkdir.split('/')[-1])\n",
    "history = model.fit_generator(\n",
    "        gen_train.generate(),\n",
    "        epochs=epochs, \n",
    "        steps_per_epoch=int(gen_train.num_batches/4), \n",
    "        callbacks=callbacks,\n",
    "        validation_data=gen_val.generate(), \n",
    "        validation_steps=int(gen_val.num_batches/4),\n",
    "        workers=cpu_count(), \n",
    "        use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
